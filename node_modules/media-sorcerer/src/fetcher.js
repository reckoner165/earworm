import { percentile, average, median, parseResponseHeaders } from './util';
import eventManager from 'eventmanager';

const responseSpeeds = [];
const failedSegments = [];
const successfulSegments = [];

/**
 * progressSpeeds is an array containing historical bandwidth data.
 * The objects contained in the array are formatted as:
 *
 * {
 *   startTime: 'The starting timestamp of the request interval',
 *   length: 'The length in seconds of the request interval',
 *   bitrate: 'The bitrate we experienced during this interval'
 * }
*/
const progressSpeeds = [];

// The maximum amount of progress speed entries allowed within the `progressSpeeds` array.
const progressSpeedMaxLogs = 100;

class Fetcher {

    /**
     * Returns the download speed over the last x number of requests
     *
     * @param  {Number} howMany number of requests to average over
     * @param  {Number} per     percentile value from 0 to 1
     * @return {Number}         speed in bps (bits per second)
     */
    static getPercentileSpeed(howMany = 5, per = 0.8) {
        const timesForPercentile = responseSpeeds.slice(-howMany);
        return percentile(timesForPercentile, per);
    }

    static getAverageSpeed(howMany = 5, weights = []) {
        const timesForAverage = responseSpeeds.slice(-howMany);
        return average(timesForAverage, weights);
    }

    static getMedianSpeed(howMany = 5) {
        const timesForMedian = responseSpeeds.slice(-howMany);
        return median(timesForMedian);
    }

    static getResponseSpeeds() {
        return responseSpeeds;
    }

    /**
     * Returns an array with the latest XHR progress download speeds.
     *
     * @return {Array} An array with `progressSpeedMaxLogs` progress speed logs
     */
    static getProgressSpeeds() {
        return progressSpeeds;
    }

    /**
     * Returns the average bitrate experienced during the last X milliseconds
     *
     * @param  {Number} time - Time interval in milliseconds to look back on
     * @return {Number} The average segment download bitrate
     */
    static getAverageBitrate(time = Infinity) {
        const cutoff = Fetcher.getTime() - time;
        const speeds = [];
        const weights = [];

        for (let index = progressSpeeds.length - 1; index >= 0; index--) {
            const progressObject = progressSpeeds[index];

            if (progressObject.startTime < cutoff) {
                break;
            }

            speeds.push(progressObject.bitrate);
        }

        for (let speedIndex = 0; speeds.length > speedIndex; speedIndex++) {
            weights.push(speeds.length - speedIndex);
        }

        return average(speeds, weights);
    }

    /**
     * Returns the failed segments array
     *
     * @return {Array}
     */
    static getFailedSegments() {
        return failedSegments;
    }

    /**
     * Returns the successful segments array
     *
     * @return {Array}
     */
    static getSuccessfulSegments() {
        return successfulSegments;
    }

    static getTime() {
        if (typeof performance !== 'undefined') {
            return performance.now();
        }

        return (new Date()).getTime();
    }

    // first retry 1.x seconds, 2nd retry 2.x and so on
    static calculateExponentialBackoff(n) {
        return (Math.pow(2, n) * 500) + (Math.round(Math.random() * 1000));
    }

    /**
     * Fetcher constructor
     *
     * @param  {Number} [options.retryCount] - The maximum request rerty count
     * @param  {Number} [options.parallel] - The maximum amount of parallel downloads
     * @param  {Boolean} [options.includeWithSpeeds] - If downloads should be used in download speed calculations
     */
    constructor({ retryCount = 3, parallel = 1, includeWithSpeeds = true } = {}) {
        this._queue = [];
        this._activeXhrRequests = new Set();
        this._retries = new WeakMap();
        this._retryCount = retryCount;
        this._running = false;
        this._processingQueue = false;
        this._parallel = parallel;
        this._includeWithSpeeds = includeWithSpeeds;

        // This per-instance WeakMap will keep track of bytes downloaded
        // and is keyed off of activeXhrRequests
        this._pendingFetchMap = new WeakMap();

        eventManager(this);

        // These are necessary to prevent us from trying to download segments
        // when we are offline. Otherwise we will try to download them and fail
        // and retry a few times and then they will never be retried once we
        // come back online.
        //
        // @see https://github.vimeows.com/player/player/issues/1868
        window.addEventListener('online', () => {
            this.start();
        });

        window.addEventListener('offline', () => {
            this.stop();

            // If we don’t abort here then all fetches in progress will fail
            // when we come back online and the mediasource scanner won’t know
            // to try to download those segments again and those requests will
            // fail if the URLs have expired.
            this.abort();
        });
    }

    get parallel() {
        return this._parallel;
    }

    set parallel(num) {
        this._parallel = num;
    }

    /**
     * Returns the downloaded bytes, total bytes and percent downloaded for
     * pending XHR requests.
     *
     * @return {Object} {[bytesTotal, bytesLoaded, percent]...}
     */
    get pendingFetches() {
        const pendingFetches = [];
        this._activeXhrRequests.forEach((xhr) => {
            if (this._pendingFetchMap.get(xhr)) {
                pendingFetches.push(this._pendingFetchMap.get(xhr));
            }
        });

        return pendingFetches;
    }

    ////////////////////
    // Public methods //
    ////////////////////

    add(segment, callback, prepend) {
        this._addSegmentToQueue(segment, callback, prepend);
        if (this._running && !this._processingQueue) {
            this._processQueue();
        }

        return this;
    }

    start() {
        if (this._running) {
            return this;
        }

        this._running = true;
        this._processQueue();

        return this;
    }

    stop() {
        this._running = false;

        return this;
    }

    /**
     * Aborts any queued requests and active requests for the passed stream
     * @param  {Stream} [stream]
     */
    abort(stream = null) {
        // if stream is null aborts = this._queue
        const aborts = this._queue.filter((data) => {
            return !stream || stream === data[0].stream;
        });

        aborts.forEach((data) => {
            const [, , identifier] = this._getIdentifierFromData(data);
            this.fire('downloadabort', identifier);
        });

        // if stream is null this._queue = []
        this._queue = this._queue.filter((data) => {
            return stream && stream !== data[0].stream;
        });

        this._activeXhrRequests.forEach((xhr) => {
            if (stream && stream !== xhr.stream) {
                return;
            }
            xhr.abort();
        });
    }
    //////////////////////
    // Internal methods //
    //////////////////////

    _insertAtPosition(segment, callback) {
        // Find the position to insert this segment
        //
        // Note that the priority number here is actually backwards aka lower
        // number means it will end up earlier in the queue. So 0 means it will
        // be placed at the beginning.
        let i = 0;
        for (; i < this._queue.length; i++) {
            const currentPriority = this._queue[i][0].priority;
            if (currentPriority > segment.priority) {
                break;
            }
        }

        this._queue.splice(i, 0, [segment, callback]);
    }

    _addSegmentToQueue(segment, callback, prepend) {
        // Prepend doesn't matter when using priority
        if (segment.hasOwnProperty('priority')) {
            this._insertAtPosition(segment, callback);
            return;
        }

        this._queue[prepend ? 'unshift' : 'push']([segment, callback]);
    }

    _processQueue() {
        if (!this._running) {
            return;
        }

        this._processingQueue = true;
        const numberToFetch = this._parallel - this._activeXhrRequests.size;
        for (let i = 0; i < numberToFetch; i++) {
            this._fetchOne();
        }
    }

    _retry(xhr, data, identifier) {
        const segment = data[0];
        const callback = data[1];

        if (!this._retries.get(segment)) {
            this._retries.set(segment, 0);
        }

        this._retries.set(segment, this._retries.get(segment) + 1);

        // Check if the maximum amount of retries have been attempted.
        if (this._retries.get(segment) > this._retryCount) {
            this._handleDownloadError(identifier, xhr.status, xhr.data.url, xhr.data.duration);
            return;
        }

        const backoff = Fetcher.calculateExponentialBackoff(this._retries.get(segment));

        console.info('Retrying', segment, 'after', backoff, 'ms');

        setTimeout(() => {
            const prepend = true;
            this.add(segment, callback, prepend);
        }, backoff);
    }

    /**
     * Manages completed XMLHttpRequest.
     *
     * @param {XMLHttpRequest} xhr
     * @param {Object} data
     * @param {Object} identifier
     * @param {Function} callback
     */
    _handleXHRResponse(xhr, data, identifier, callback) {
        // For 5xx errors retry
        if (xhr.status >= 500 && xhr.status < 600) {
            this._retry(xhr, data, identifier);
            return;
        }

        // For 4xx errors trigger an error
        if (xhr.status >= 400 && xhr.status < 500) {
            this._handleDownloadError(identifier, xhr.status, xhr.data.url, xhr.data.duration);
            return;
        }

        this.fire('downloadend', identifier, {
            headers: parseResponseHeaders(xhr.getAllResponseHeaders())
        });
        successfulSegments.push({
            url: xhr.data.url,
            status: xhr.status,
            duration: xhr.data.duration
        });
        callback.call(this, new Uint8Array(xhr.response));
    }

    /**
     * Called when a segment download request has
     * returned a 404 status code.
     *
     * @param   {Object} identifier
     * @param   {Number} status
     * @param   {String} url
     * @param   {Number} duration
     */
    _handleDownloadError(identifier, status, url, duration) {
        failedSegments.push({
            url,
            status,
            duration
        });
        this.fire('downloaderror', identifier, status);
    }

    _getIdentifierFromData(data) {
        // Data looks like:
        // [{
        //     url,
        //     byteRange,
        //     id
        // },
        // callback
        // ]
        const callback = data[1];
        const segment = data[0];
        let identifier = segment;

        if (segment.id) {
            identifier = segment.id;
        }

        return [segment.url, segment.byteRange, identifier, callback];
    }

    _continueProcessingQueue() {
        if (this._activeXhrRequests.size === 0 && this._queue.length === 0) {
            this._processingQueue = false;
            return;
        }

        if (this._activeXhrRequests.size < this._parallel) {
            this._processQueue();
        }
    }

    _fetchOne() {
        if (this._queue.length === 0) {
            this._processingQueue = false;
            return;
        }

        let requestSendTime = null;
        const data = this._queue.shift();
        const [url, byteRange, identifier, callback] = this._getIdentifierFromData(data);
        const includeWithSpeeds = data[0].includeWithBandwidthChecks;
        const startTime = Fetcher.getTime();
        const xhr = new XMLHttpRequest();
        xhr.stream = data[0].stream;
        xhr.data = {};
        xhr.data.url = url;

        let lastBytesLoaded = 0;
        let lastTimeRecorded = Fetcher.getTime();

        // Cannot use initial progress interval since it counts latency
        let index = 0;

        xhr.addEventListener('progress', (req) => {
            if (req.lengthComputable) {
                // Bits loaded since last progress
                const bitsLoaded = (req.loaded - lastBytesLoaded) * 8;
                const time = Fetcher.getTime();
                const durationMS = time - lastTimeRecorded;
                const durationSeconds = durationMS / 1000;
                const bitrate = bitsLoaded / durationSeconds;

                const intervalObject = {
                    startTime: lastTimeRecorded,
                    length: durationMS,
                    bitrate,
                    index
                };

                if (index > 0) {
                    // Avoid appending too much to the progressSpeeds tracking array.
                    if (progressSpeeds.length >= progressSpeedMaxLogs) {
                        progressSpeeds.shift();
                    }

                    progressSpeeds.push(intervalObject);
                }

                lastTimeRecorded = time;
                lastBytesLoaded = req.loaded;
                index += 1;

                this._pendingFetchMap.set(xhr, {
                    bytesTotal: req.total,
                    bytesLoaded: req.loaded,
                    percent: req.loaded / req.total,
                    identifier
                });

                this.fire('progress', identifier);
            }
        });

        xhr.open('GET', url, true);
        xhr.responseType = 'arraybuffer';

        if (byteRange) {
            xhr.setRequestHeader('Range', `bytes=${byteRange}`);
        }

        // Called when the XMLHttpRequest transaction completes successfully.
        xhr.onload = (e) => {
            const duration = Date.now() - requestSendTime;
            xhr.data.duration = duration;
            this._activeXhrRequests.delete(xhr);

            // If a segment is done being downloaded, clear limbo
            this._pendingFetchMap.delete(xhr);

            const elapsedTimeInSeconds = (Fetcher.getTime() - startTime) / 1000;

            // If the size is greater than 40kb then include it in the
            // response speeds.  This is cause for init segments the size
            // is smaller and a lot of the response time is network time so
            // the actual calculated bit rate is not useful.
            const size = e.target.response.byteLength;
            if (size > 40960) {
                const sizeInBits = size * 8;
                const bitsPerSecond = sizeInBits / elapsedTimeInSeconds;

                // only keep last 100
                if (responseSpeeds.length > 100) {
                    responseSpeeds.shift();
                }

                if (this._includeWithSpeeds && includeWithSpeeds) {
                    responseSpeeds.push(bitsPerSecond);
                }
            }

            this._handleXHRResponse(xhr, data, identifier, callback);
            this._continueProcessingQueue();
        };

        // Fires when there is a failure on the network level.
        // If the error only exists on the application level,
        // e.g., an HTTP error code is sent, then onload still fires.
        xhr.onerror = () => {
            const duration = Date.now() - requestSendTime;
            xhr.data.duration = duration;
            this._activeXhrRequests.delete(xhr);
            this._pendingFetchMap.delete(xhr);
            this._retry(xhr, data, identifier);
            this._continueProcessingQueue();
        };

        // Called when an XMLHttpRequest transaction is aborted,
        // such as when the XMLHttpRequest.abort() function is called.
        xhr.onabort = () => {
            const duration = Date.now() - requestSendTime;
            xhr.data.duration = duration;
            failedSegments.push({
                url,
                status: 'abort',
                duration
            });
            // If a segment has been aborted, clear limbo
            this._pendingFetchMap.delete(xhr);

            this._activeXhrRequests.delete(xhr);

            this.fire('downloadabort', identifier);

            if (this._activeXhrRequests.size === 0 && this._queue.length === 0) {
                this._processingQueue = false;
            }

            // This is because there might be objects in the queue
            // that belong to the non-aborted stream that we want to examine
            this._continueProcessingQueue();
        };

        this.fire('downloadstart', identifier);

        this._activeXhrRequests.add(xhr);
        requestSendTime = Date.now();
        xhr.send();
    }
}

export default Fetcher;
